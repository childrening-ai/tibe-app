import streamlit as st
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import pandas as pd
import datetime
from streamlit_calendar import calendar
from ics import Calendar, Event
import time
import re

# 1. é é¢åŸºæœ¬è¨­å®š
st.set_page_config(
    page_title="2026 æ›¸å±•æ’ç¨‹ç¥å™¨",
    page_icon="ğŸ“…",
    layout="wide"
)

# --- è¨­å®šå€ ---
SHEET_NAME = "2026åœ‹éš›æ›¸å±•è¡Œäº‹æ›†"
WORKSHEETS_TO_LOAD = ["åœ‹éš›æ›¸å±•"]

# --- åˆå§‹åŒ– Session State ---
if "calendar_focus_date" not in st.session_state:
    st.session_state.calendar_focus_date = "2026-02-04" 

if "prev_selection_counts" not in st.session_state:
    st.session_state.prev_selection_counts = {}

# --- 2. é€£ç·šèˆ‡è³‡æ–™è®€å– ---
@st.cache_data(ttl=300)
def load_sheet_data():
    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    try:
        # è®€å– Secrets
        if "gcp_service_account" in st.secrets:
            creds_dict = dict(st.secrets["gcp_service_account"])
            if "private_key" in creds_dict:
                 creds_dict["private_key"] = creds_dict["private_key"].replace("\\n", "\n")
            creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
        else:
            creds = ServiceAccountCredentials.from_json_keyfile_name("secrets.json", scope)
        
        client = gspread.authorize(creds)
        
        try:
            spreadsheet = client.open(SHEET_NAME)
        except gspread.SpreadsheetNotFound:
            return None, f"æ‰¾ä¸åˆ°æª”æ¡ˆï¼š{SHEET_NAME}"

        all_frames = []
        STANDARD_COLS = ["æ—¥æœŸ", "æ™‚é–“", "æ´»å‹•åç¨±", "åœ°é»", "ä¸»è¬›äºº", "ä¸»æŒäºº", "é¡å‹", "å‚™è¨»", "è©³ç´°å…§å®¹"]

        for ws_name in WORKSHEETS_TO_LOAD:
            try:
                worksheet = spreadsheet.worksheet(ws_name)
                data = worksheet.get_all_values()
                if len(data) < 2: continue
                
                df = pd.DataFrame(data[1:], columns=data[0])
                df['ä¾†æº'] = ws_name 
                df.columns = [c.strip() for c in df.columns]
                
                if "ä¸»è¬›äºº" not in df.columns and "è¬›è€…" in df.columns:
                    df.rename(columns={"è¬›è€…": "ä¸»è¬›äºº"}, inplace=True)

                for col in STANDARD_COLS:
                    if col not in df.columns:
                        df[col] = "" 
                
                df = df.fillna("")
                
                # ğŸ”¥ ä¿®æ­£ ID ç”Ÿæˆï¼šæ”¹ç”¨ç´”å­—ä¸²æ‹¼æ¥ï¼Œæ¯” hash æ›´ç©©å®š
                df['id'] = df.apply(lambda x: f"{x['æ—¥æœŸ']}_{x['æ™‚é–“']}_{x['æ´»å‹•åç¨±']}", axis=1)
                
                all_frames.append(df)
            except Exception as e:
                print(f"Skipping {ws_name}: {e}")
                pass

        if not all_frames: return pd.DataFrame(), "ç„¡è³‡æ–™"
        final_df = pd.concat(all_frames, ignore_index=True)
        return final_df, "Success"

    except Exception as e:
        return None, str(e)

# --- ğŸ”¥ ä¿®æ­£ç‰ˆï¼šæ™‚é–“è§£æå·¥å…· ---
def parse_datetime_range(date_str, time_str):
    try:
        clean_date = str(date_str).split(" ")[0].strip()
        # æ¸…ç†æ™‚é–“å­—ä¸²
        clean_time = str(time_str).replace("ï¼š", ":").replace("~", "-").replace(" ", "")
        
        if "-" in clean_time:
            parts = clean_time.split("-")
            start_t = parts[0]
            end_t = parts[1]
        else:
            start_t = clean_time
            end_t = clean_time 
        
        # ç°¡å–®è£œæ•‘ï¼šå¦‚æœæ™‚é–“åªæœ‰ "14:00"ï¼Œè£œä¸Šç§’æ•¸è®Šæˆ "14:00:00" æ¯”è¼ƒä¿éšªï¼Œæˆ–è€…ä¾æ ¼å¼åˆ¤æ–·
        # é€™è£¡å‡è¨­æ ¼å¼æ˜¯ HH:MM
        
        start_dt_str = f"{clean_date} {start_t}"
        end_dt_str = f"{clean_date} {end_t}"
        
        # ğŸ”¥ ä¿®æ­£è™•ï¼šé€™è£¡è£œä¸Šäº†ä¸€å€‹ç©ºç™½ï¼Œå°æ‡‰ f-string è£¡çš„ç©ºç™½
        fmt = "%Y-%m-%d %H:%M" 
        
        try:
            start_dt = datetime.datetime.strptime(start_dt_str, fmt)
            end_dt = datetime.datetime.strptime(end_dt_str, fmt)
        except ValueError:
            # å¦‚æœè§£æå¤±æ•—ï¼Œè©¦è©¦çœ‹æœ‰æ²’æœ‰ç§’æ•¸
            fmt_sec = "%Y-%m-%d %H:%M:%S"
            try:
                start_dt = datetime.datetime.strptime(start_dt_str, fmt_sec)
                end_dt = datetime.datetime.strptime(end_dt_str, fmt_sec)
            except:
                return None, None
        
        return start_dt, end_dt
    except:
        return None, None

# --- ä¸»ç¨‹å¼ ---

st.title("ğŸ“… 2026 æ›¸å±•æ’ç¨‹ç¥å™¨")
st.markdown("å·¦å´å‹¾é¸æ´»å‹•ï¼Œå³å´å³æ™‚é è¦½è¡Œç¨‹ï¼(æ”¯æ´ **åŒ¯å‡ºæ‰‹æ©Ÿè¡Œäº‹æ›†**)")

# è®€å–è³‡æ–™
raw_df, msg = load_sheet_data()

if raw_df is None or raw_df.empty:
    st.error(f"âš ï¸ è³‡æ–™è®€å–å¤±æ•—ï¼š{msg}")
    st.stop()

# é è™•ç†
proc_df = raw_df.copy()
start_list, end_list = [], []

for _, row in proc_df.iterrows():
    s, e = parse_datetime_range(row['æ—¥æœŸ'], row['æ™‚é–“'])
    start_list.append(s)
    end_list.append(e)

proc_df['start_dt'] = start_list
proc_df['end_dt'] = end_list

# --- ç‰ˆé¢é…ç½® ---
col_list, col_cal = st.columns([0.6, 0.4])
all_selected_ids = []
current_selection_counts = {}

# --- å·¦å´ï¼šæ´»å‹•æ¸…å–® ---
with col_list:
    st.subheader("1. å‹¾é¸æ´»å‹• âœ…")
    
    with st.expander("ğŸ” é€²éšç¯©é¸", expanded=False):
        f_loc = st.multiselect("åœ°é»", options=sorted(list(set(proc_df['åœ°é»'].astype(str)))))
        f_type = st.multiselect("é¡å‹", options=sorted(list(set(proc_df['é¡å‹'].astype(str)))))
        f_key = st.text_input("é—œéµå­—æœå°‹")

    mask = [True] * len(proc_df)
    if f_loc: mask &= proc_df['åœ°é»'].isin(f_loc)
    if f_type: mask &= proc_df['é¡å‹'].isin(f_type)
    if f_key: 
        mask &= (
            proc_df['æ´»å‹•åç¨±'].str.contains(f_key, case=False) | 
            proc_df['ä¸»è¬›äºº'].str.contains(f_key, case=False) |
            proc_df['ä¸»æŒäºº'].str.contains(f_key, case=False)
        )
    
    filtered_df = proc_df[mask]
    unique_dates = sorted(list(set(filtered_df['æ—¥æœŸ'].unique())))
    
    if not unique_dates:
        st.info("æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„æ´»å‹•")
    else:
        tab_names = [d[5:] if len(str(d))>5 else str(d) for d in unique_dates]
        tabs = st.tabs(tab_names)
        
        for i, date_str in enumerate(unique_dates):
            with tabs[i]:
                day_df = filtered_df[filtered_df['æ—¥æœŸ'] == date_str].copy()
                day_df = day_df.sort_values(by='æ™‚é–“')
                
                if "åƒåŠ " not in day_df.columns:
                    day_df.insert(0, "åƒåŠ ", False)
                
                edited_day_df = st.data_editor(
                    day_df,
                    column_config={
                        "åƒåŠ ": st.column_config.CheckboxColumn("åƒåŠ ", width="small"),
                        "æ™‚é–“": st.column_config.TextColumn("æ™‚é–“", width="medium"),
                        "æ´»å‹•åç¨±": st.column_config.TextColumn("æ´»å‹•åç¨±", width="large"),
                        "åœ°é»": st.column_config.TextColumn("åœ°é»", width="medium"),
                        "ä¸»è¬›äºº": st.column_config.TextColumn("ä¸»è¬›äºº", width="medium"),
                        "é¡å‹": st.column_config.TextColumn("é¡å‹", width="small"),
                        "ä¸»æŒäºº": None, "è©³ç´°å…§å®¹": None, "å‚™è¨»": None, "ä¾†æº": None, 
                        "id": None, "start_dt": None, "end_dt": None, "æ—¥æœŸ": None
                    },
                    hide_index=True,
                    key=f"editor_{date_str}"
                )
                
                selected_rows = edited_day_df[edited_day_df["åƒåŠ "] == True]
                
                # è‡ªå‹•è·³è½‰æ—¥æ›†é‚è¼¯
                current_count = len(selected_rows)
                current_selection_counts[date_str] = current_count
                prev_count = st.session_state.prev_selection_counts.get(date_str, 0)
                
                if current_count != prev_count:
                    st.session_state.calendar_focus_date = date_str
                
                if not selected_rows.empty:
                    all_selected_ids.extend(selected_rows['id'].tolist())

    st.session_state.prev_selection_counts = current_selection_counts

# --- å³å´ï¼šæ—¥æ›† & åŒ¯å‡º ---
with col_cal:
    st.subheader("2. è¡Œç¨‹é è¦½ ğŸ—“ï¸")
    
    # é€™è£¡éæ¿¾å‡ºã€Œè¢«å‹¾é¸ã€ä¸”ã€Œæ™‚é–“è§£ææˆåŠŸã€çš„è³‡æ–™
    final_selected = proc_df[
        (proc_df['id'].isin(all_selected_ids)) & 
        (proc_df['start_dt'].notnull()) # ç¢ºä¿æ™‚é–“æœ‰æ•ˆ
    ]
    
    # Debug è¨Šæ¯ï¼šå‘Šè¨´ä½¿ç”¨è€…åˆ°åº•æŠ“åˆ°äº†å¹¾ç­†
    if len(all_selected_ids) > 0 and len(final_selected) == 0:
        st.warning(f"âš ï¸ æ‚¨å‹¾é¸äº† {len(all_selected_ids)} ç­†ï¼Œä½†æ™‚é–“æ ¼å¼ä¼¼ä¹éƒ½ç„¡æ³•è§£æï¼Œç„¡æ³•é¡¯ç¤ºåœ¨æ—¥æ›†ä¸Šã€‚")
    elif len(final_selected) > 0:
        st.success(f"å·²é¡¯ç¤º {len(final_selected)} å ´æ´»å‹•")

    cal_events = []
    for _, row in final_selected.iterrows():
        bg_color = "#3788d8"
        if str(row['ä¾†æº']) != "åœ‹éš›æ›¸å±•": bg_color = "#ff9f43"
        
        cal_events.append({
            "title": row['æ´»å‹•åç¨±'],
            "start": row['start_dt'].isoformat(),
            "end": row['end_dt'].isoformat(),
            "backgroundColor": bg_color,
            "borderColor": bg_color
        })

    initial_view_date = st.session_state.calendar_focus_date

    calendar_options = {
        "initialView": "timeGridDay",
        "initialDate": initial_view_date,
        "headerToolbar": {
            "left": "prev,next",
            "center": "title",
            "right": "timeGridDay,listDay"
        },
        "slotMinTime": "09:00:00",
        "slotMaxTime": "21:00:00",
        "height": "auto",
        "nowIndicator": True
    }
    
    calendar(events=cal_events, options=calendar_options, key=f"main_calendar_{initial_view_date}")
    
    st.divider()
    st.subheader("3. å¸¶èµ°è¡Œç¨‹ ğŸ’")
    
    if final_selected.empty:
        st.caption("ğŸ‘ˆ è«‹å…ˆå‹¾é¸æ´»å‹•")
    else:
        c1, c2, c3 = st.columns(3)
        
        # 1. ICS
        with c1:
            cal_obj = Calendar()
            for _, row in final_selected.iterrows():
                e = Event()
                e.name = f"{row['æ´»å‹•åç¨±']} ({row['åœ°é»']})"
                if row['start_dt']: e.begin = row['start_dt']
                if row['end_dt']: e.end = row['end_dt']
                e.location = str(row['åœ°é»'])
                
                desc_parts = []
                if row['ä¸»è¬›äºº']: desc_parts.append(f"ä¸»è¬›: {row['ä¸»è¬›äºº']}")
                if row['ä¸»æŒäºº']: desc_parts.append(f"ä¸»æŒ: {row['ä¸»æŒäºº']}")
                if row['å‚™è¨»']: desc_parts.append(f"å‚™è¨»: {row['å‚™è¨»']}")
                if row['è©³ç´°å…§å®¹']: desc_parts.append(f"\n{row['è©³ç´°å…§å®¹']}")
                
                e.description = "\n".join(desc_parts)
                cal_obj.events.add(e)
            
            st.download_button("ğŸ“… æ‰‹æ©Ÿè¡Œäº‹æ›†", data=cal_obj.serialize(), file_name="tibe_2026.ics", mime="text/calendar")

        # 2. CSV
        with c2:
            out_cols = ["æ—¥æœŸ", "æ™‚é–“", "æ´»å‹•åç¨±", "åœ°é»", "ä¸»è¬›äºº", "ä¸»æŒäºº", "å‚™è¨»", "è©³ç´°å…§å®¹"]
            valid_cols = [c for c in out_cols if c in final_selected.columns]
            csv_data = final_selected[valid_cols].to_csv(index=False).encode('utf-8-sig')
            st.download_button("ğŸ–¨ï¸ åˆ—å°ç”¨è¡¨æ ¼", data=csv_data, file_name="tibe_2026_schedule.csv", mime="text/csv")

        # 3. Text
        with c3:
            txt_out = "ğŸ“š 2026 æ›¸å±•è¡Œç¨‹è¡¨ ğŸ“š\n"
            sorted_rows = final_selected.sort_values(by=['æ—¥æœŸ', 'æ™‚é–“'])
            curr_date = ""
            for _, row in sorted_rows.iterrows():
                if row['æ—¥æœŸ'] != curr_date:
                    txt_out += f"\nğŸ“… {row['æ—¥æœŸ']}\n" + "-"*15 + "\n"
                    curr_date = row['æ—¥æœŸ']
                txt_out += f"{row['æ™‚é–“']} | {row['æ´»å‹•åç¨±']}\n"
                txt_out += f"ğŸ“ {row['åœ°é»']}"
                if row['ä¸»è¬›äºº']: txt_out += f" | ğŸ—£ï¸ {row['ä¸»è¬›äºº']}"
                txt_out += "\n"
            
            st.download_button("ğŸ’¬ æ–‡å­—æ‡¶äººåŒ…", data=txt_out, file_name="tibe_text.txt", mime="text/plain")